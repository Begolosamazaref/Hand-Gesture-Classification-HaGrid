# Hand Gesture Classification â€” HaGrid

A machine learning project that classifies hand gestures using hand landmark data extracted from the [HaGrid dataset](https://github.com/hukenovs/hagrid).

---

## ğŸ“ Project Structure

```
ML_Project/
â”œâ”€â”€ Notebook/
â”‚   â”œâ”€â”€ hand_gesture_classification.ipynb   # Main notebook 
â”‚   â””â”€â”€ hand_landmarks_data.csv             # Extracted hand landmark features dataset
â”œâ”€â”€ Screenshots/
â”‚   â”œâ”€â”€ class_distribution.png              # Distribution of gesture classes
â”‚   â”œâ”€â”€ confusion_matrices.png              # Confusion matrices for all models
â”‚   â”œâ”€â”€ hand_landmarks_per_class.png        # Landmark visualizations per class
â”‚   â””â”€â”€ normalization_comparison.png        # Effect of feature normalization
â”œâ”€â”€ Videos/
â”‚   â”œâ”€â”€ Input - Made with Clipchamp.mp4     # input video
â”‚   â””â”€â”€ output.mp4                          # Model prediction output video
â””â”€â”€ pkl_files/
    â”œâ”€â”€ MLP.pkl                             # Best trained MLP model
    â”œâ”€â”€ label_encoder.pkl                   # Label encoder for gesture classes
    â””â”€â”€ scaler.pkl                          # StandardScaler for feature normalization
```

---

## ğŸ”„ Workflow Overview

```
MediaPipe Hand Landmark Extraction (21 landmarks Ã— 3 coords = 63 features)
       â†“
Feature Engineering & Normalization (StandardScaler)
       â†“
Train/Test Split
       â†“
Multiple Model Training (MLP, SVM, RF, KNN)
       â†“
Best Model â†’ pkl_files/MLP.pkl
       â†“
Inference on Video
```

---

## Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/Begolosamazaref/Hand-Gesture-Classification-HaGrid.git
cd Hand-Gesture-Classification-HaGrid/ML_Project
```

### 2. Create and activate the environment

```bash
conda create -n hand_gesture python=3.10
conda activate hand_gesture
```

### 3. Install dependencies

```bash
pip install scikit-learn mediapipe pandas numpy matplotlib opencv-python jupyter
```

### 4. Run the notebook

```bash
jupyter lab Notebook/hand_gesture_classification.ipynb
```

## ğŸŒ¿ Branches

| Branch | Contents |
|--------|----------|
| `main` | Clean project files: notebook, dataset, models, screenshots, videos |
| `research` | Full MLflow experiment data: runs, model artifacts, registry, screenshots |

---

## ğŸ› ï¸ Tech Stack

- **MediaPipe** â€” hand landmark extraction
- **scikit-learn** â€” model training and evaluation
- **OpenCV** â€” video processing
- **Pandas / NumPy** â€” data handling
- **Matplotlib** â€” visualization

---

## ğŸ‘¤ Author

**Begolosamazaref**  
ITI Diploma  
[GitHub Profile](https://github.com/Begolosamazaref)
